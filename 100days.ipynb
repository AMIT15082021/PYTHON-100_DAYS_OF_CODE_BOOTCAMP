{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new user is being created\n",
      "angela\n",
      "new user is being created\n",
      "Tommy\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self,user_id):\n",
    "        self.id=user_id\n",
    "    \n",
    "user_1=User() # Object  created\n",
    "user_1.id=\"001\"  # Attribute create \n",
    "user_1.username=\"angela\" # Another attribute created\n",
    "\n",
    "print(user_1.username)\n",
    "\n",
    "user_2=User() # Object  created\n",
    "user_2.id=\"002\"  # Attribute create \n",
    "user_2.username=\"Tommy\" # Another attribute created\n",
    "\n",
    "print(user_2.username)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date : 8th September 2023 \n",
    "### Agenda - Section 25- Working with CSV data and Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day,temp,condition\n",
      "Monday,12,Sunny\n",
      "Tuesday,14,Rain\n",
      "Wednesday,15,Rain\n",
      "Thursday,14,Cloudy\n",
      "Friday,21,Sunny\n",
      "Saturday,22,Sunny\n",
      "Sunday,24,Sunny\n"
     ]
    }
   ],
   "source": [
    "file = open(\"weather_data.csv\")\n",
    "contents=file.read() # read method returns the contents of the file as a string \n",
    "print(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day,temp,condition\\n', 'Monday,12,Sunny\\n', 'Tuesday,14,Rain\\n', 'Wednesday,15,Rain\\n', 'Thursday,14,Cloudy\\n', 'Friday,21,Sunny\\n', 'Saturday,22,Sunny\\n', 'Sunday,24,Sunny']\n"
     ]
    }
   ],
   "source": [
    "with open(\"weather_data.csv\") as file:  # using this syntax we don't need to add a file.close()\n",
    "    contents=file.readlines() # read method returns the contents of the file as a string , readlines()turns each line as an item in a list\n",
    "    print(contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if I go ahead and print my data, then you can see I've got this list now where each item is a row in that list.  \n",
    "*But as you can imagine, it would be pretty painful to work with the data, which is all in a string format.*  \n",
    "And they are still separated by commas. It would take a lot of cleaning to actually be able to extract each column and each row. So what can we do instead? Well, there's actually a inbuilt library that helps us with CSVs because Python is a language that's used really heavily for data processing, data analysis.\n",
    "\n",
    "### There's a lot of great tools for working with tabula data, like our weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "14\n",
      "15\n",
      "14\n",
      "21\n",
      "22\n",
      "24\n",
      "[12, 14, 15, 14, 21, 22, 24]\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "with open(\"weather_data.csv\") as data_file:  # using this syntax we don't need to add a file.close()\n",
    "    data=csv.reader(data_file)   # creates an object named data\n",
    "    temperatures=[]\n",
    "    #print(data)\n",
    "    for row in data:\n",
    "        #print(type(row[1]))\n",
    "        if row[1] != \"temp\":\n",
    "           print(row[1])\n",
    "           temperatures.append(int(row[1]))\n",
    "    print(temperatures)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much faff was involved in just simply getting a single column of data. What are we going to do if we have more data, more complex data with way more columns, way more rows.  \n",
    "And we want to do more interesting things with it? This is going to be quite painful to work with.  \n",
    "This is the point where we want to get the help of some *pandas.* \n",
    "\n",
    "It is good to know that some libraries in Pyhton are *inbuilt* and don't need to be imported whereas others like csv,numpy, pandas etc are not and hence need to imported.  \n",
    "\n",
    "\n",
    "Note: For opening Excel based files like  name.xlsx, we need to install the dependency called openpyxl ---- *conda install openpyxl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "0     Sunny\n",
      "1      Rain\n",
      "2      Rain\n",
      "3    Cloudy\n",
      "4     Sunny\n",
      "5     Sunny\n",
      "6     Sunny\n",
      "Name: condition, dtype: object\n",
      "0     Sunny\n",
      "1      Rain\n",
      "2      Rain\n",
      "3    Cloudy\n",
      "4     Sunny\n",
      "5     Sunny\n",
      "6     Sunny\n",
      "Name: condition, dtype: object\n",
      "Empty DataFrame\n",
      "Columns: [day, temp, condition]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"weather_data.csv\")\n",
    "#data=pd.read_excel(\"holdings-xl.xlsx\") \n",
    "#data=pd.read_csv(\"holdings.csv\")\n",
    "print(data[\"temp\"].max())\n",
    "\n",
    "# another way to access column data is \n",
    "print(data[\"condition\"])\n",
    "print(data.condition) # does the same thing as the statement in the above line\n",
    "\n",
    "# Get data in row \n",
    "#print(data[data.day==\"Monday\"])\n",
    "print(data[data.temp == \"12\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Panda's doing here is __*it takes that first row to be the names of each column*__ and it automatically knows how to find the data when you just specify the name of the column like this.  \n",
    "\n",
    "So three lines versus eight lines, and we get better formatting. It's no wonder that most Python developers, as soon as they encounter a CSV fault, they will start using pandas to work with it no matter how simple the task or project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to change the *last (only works for the last commit)* message of a commit that you've already pushed to your remote branch ?  \n",
    "Example : the wrong message was : git commit -m \"this is the main pyhtin jupyter notebook\"  \n",
    "And what we want is : git commit -m \"This is the main Python/Jupyter notebook\"  \n",
    "So what do we do :  \n",
    "Step 1: git commit --amend -m \"This is the main Python/Jupyter notebook\"   \n",
    "Step 2: git push --force origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to sync an file which has been edited and hence changed from the local machine?  \n",
    "In this case the file I am working on has been edited  \n",
    "Step 1: git add 100days.ipynb  \n",
    "Step 2 : git commit -m \"Updated jupyter notebook\"  # Here we have changed the message which is in double quotes as per our desire  \n",
    "Step 3: git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
